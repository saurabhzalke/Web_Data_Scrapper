{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a program which implements data\n",
    "# scrapping using BeautifulSoup which is \n",
    "# a Python library for data scrapping.\n",
    "\n",
    "# Loading necessary modules \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r=requests.get(\"http://www.pythonhow.com/real-estate/rock-springs-wy/LCWYROCKSPRINGS/\",headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})\n",
    "c= r.content\n",
    "soup =BeautifulSoup(c,\"html.parser\")\n",
    "\n",
    "all = soup.find_all(\"div\", {\"class\":\"propertyRow\"})\n",
    "all[0].find(\"h4\", {\"class\":\"propPrice\"}).text.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "\n",
    "page_nr =soup.find_all(\"a\", {\"class\":\"Page\"})[-1].text\n",
    "# print(page_nr)\n",
    "\n",
    "# Using a list to store the scrapped data.\n",
    "l=[]\n",
    "\n",
    "# If site has multiple pages, the program iterates through \n",
    "base_url=\"http://www.pythonhow.com/real-estate/rock-springs-wy/LCWYROCKSPRINGS/t=0&s=\" #URL of site to be scrapped\n",
    "\n",
    "for page in range(0, int(page_nr)*10, 10):\n",
    "    r= requests.get(base_url+str(page)+\".html\",headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})\n",
    "    c= r.content\n",
    "    soup= BeautifulSoup(c, \"html.parser\")\n",
    "    all =soup.find_all(\"div\",{\"class\":\"propertyRow\"})\n",
    "    \n",
    "    for item in all:\n",
    "        d={}\n",
    "        \n",
    "        d[\"Address\"] = item.find_all(\"span\",{\"class\", \"propAddressCollapse\"})[0].text\n",
    "        d[\"Locality\"] = item.find_all(\"span\",{\"class\", \"propAddressCollapse\"})[1].text\n",
    "        d[\"Price\"] = item.find(\"h4\", {\"class\":\"propPrice\"}).text.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "        try:\n",
    "            d[\"Beds\"] = item.find(\"span\", {\"class\", \"infoBed\"}).find(\"b\").text\n",
    "        except:\n",
    "            d[\"Beds\"]= None\n",
    "\n",
    "        try:\n",
    "            d[\"Area\"] = item.find(\"span\", {\"class\", \"infoSqft\"}).find(\"b\").text\n",
    "        except:\n",
    "            d[\"Area\"] = None\n",
    "\n",
    "        try:\n",
    "            d[\"Full Bath\"] = item.find(\"span\", {\"class\", \"infoValueFullBath\"}).find(\"b\").text\n",
    "        except:\n",
    "            d[\"Full Bath\"] = None\n",
    "\n",
    "        try:\n",
    "            d[\"Half Bath\"] = item.find(\"span\", {\"class\", \"infoValueHalfBath\"}).find(\"b\").text\n",
    "        except:\n",
    "            d[\"Half Bath\"] = None\n",
    "\n",
    "        for column_group in item.find_all(\"div\",{\"class\":\"columnGroup\"}):\n",
    "            for feature_group, feature_name in zip(column_group.find_all(\"span\", {\"class\":\"featureGroup\"}), column_group.find_all(\"span\", {\"class\":\"featureName\"})):\n",
    "                if \"Lot Size\" in feature_group.text:\n",
    "                    d[\"Lot Size\"] = feature_name.text    \n",
    "\n",
    "        l.append(d)\n",
    "    \n",
    "#Converting data into a data frame.\n",
    "import pandas\n",
    "df = pandas.DataFrame(l)\n",
    "\n",
    "#Outputting the data to file.\n",
    "df.to_csv(\"Fetched_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
